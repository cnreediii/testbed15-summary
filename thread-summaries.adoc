[[thread-summaries]]

== Thread Summaries

The following are overviews of each of the major Testbed 15 thread activities.

[[SFC]]

=== Thread 1: Secure Data and Federated Clouds (SFC)

==== Data Centric Security

*Explore How Data Centric Security principals can be applied at the feature level in a geospatial data store.*

Data-centric security is an approach to security that emphasizes the security of the data itself rather than the security of networks, servers, or applications. In Testbed-15, the focus was on how security works at a Feature Level as well as implications as a data burden on the network. With focus on the actual interactions and general workflows, Testbed-15 work sought to answer the question of how data centric security can be applied to OGC standards based architectures:

* How does data centric security works with OGC standards and best practices?
* Which elements are already supported and how?
* Which modifications to existing standards or best practices are necessary to exploit full potential of data centric security?

To answer those questions, the particpants examined the use of encrypted containers in combination with geospatial data using the encoding for an OGC API for Features and the Web Feature Service (WFS) FeatureCollection structure. Within that context, the particants looked at the use of encrypted container formats such as NATO STANAG 4778 "Information on standard Metadata Binding" with metadata as defined in NATO STANAG 4774 "Confidentiality Metadata Label Syntax" to permit the sharing of sensitive information between allies.

image::images/GepPEP as a Proxy for STANAG 4778.png[image,width=326,height=308]
* Geospatial Policy Enforcement Point (GeoPEP) as a Proxy for STANAG 4778 *

In general, the work performed in Testbed 15 was able to demonstrate that with a security proxy and an OGC API - Features service, an implementation can satisfy the requirements for a data centric security model. The Engineering Report documents the results of implementing three scenarios. Scenarios one and two show a backward compatible method for implementing data centric security. One requirement that was not completely investigated in the first two scenarios was encryption of the data from the author to storage. 

The following are additional information resources regarding the Data Centric Security task.

[options="header"]
|===
| Information Resource | Location of resource
| Requirements | https://portal.opengeospatial.org/files/?artifact_id=82290#DataCentricSecurity[CFP Sponsor Requirements for Data Centric Security]
| Engineering Report |http://docs.opengeospatial.org/per/19-016r1.html[Data Centric Security Engineering Report]
| Power Point Presentation | link:https://github.com/cnreediii/testbed15-summary/blob/master/slides/Testbed%2015%20Data%20Centric%20Security.pdf[Slide presentation]
| Short Video | link:https://www.youtube.com/watch?v=5_ynVa8ZMY4&list=PLQsQNjNIDU85HBDZWc8aE7EvQKE5nIedK&index=7&t=0s[Youtube Video]
|===

[[FCA]]

==== Federated Cloud Analytics

*Research how emerging technologies and architectures featuring distributed cloud environments can be successfully integrated with OGC standards*

The advent of the cloud computing era has fundamentally changed how people and organizations view computing — and more specifically how people and organizations interact with the resources that they care about: data and services. All computing resources, including clouds, exist in some type of administrative domain wherein access management can be done. As long as resources are all in the same administrative domain, managing access is straight-forward. However, with the continued development of our interconnected world, it is becoming increasingly common that data and services desired by a user exist across different administrative domains.

Easily accessing resources distributed across different administrative domains is a challenge. The naive approach is for an individual to maintain n different accounts and credentials for n different organizations. A more effective approach is federation.

Simply put, a federation enables a set of participating organizations to selectively share data and resources for specific purposes. The goal is to make federated environments as seamless, transparent, and easy to use as a single centralized environment. More precisely, a federation is a security and collaboration context wherein participants can define, agree up on, and enforce joint resource discovery and access policies.

Previous OGC Testbeds addressed a number of issues related to supporting analytic workflows where the data and analytics are hosted or deployed in an ad-hoc manner on multiple heterogeneous clouds that belong to different administrative domains. In this Testbed activity the OGC began to assess the sufficiency of that body of work and identify areas were additional work is needed. This assessment was performed through a proof of concept executing a non-trivial analytic mission leveraging data and analytics hosted on two or more clouds.

Of particular interest in this context are three aspects. Firstly, the handling of security in federations. Second, how the Testbed-13 and Testbed-14 research results of "bringing applications to the data" relate to SCALE and SEED. SCALE is an open source system that provides management and scheduling of automated processing on a cluster of machines. SCALE uses the SEED specification to aid in the discovery and consumption of processes packaged in a Docker containers. Third, the role of blockchain and distributed ledger technologies in the context of handling provenance in federations.

To meet this objective, this task was organized in four separate sub-tasks. The following research questions were addressed by the particpants:

* Federated Security: Can the NIST/IEEE Federated Cloud architecture be validated (or invalidated) in a typical federated clouds analytics scenario that includes separate cloud environments? How can the Mediation Server concept developed in Testbed-14 be further enhanced to a fully functional Federation Manager in the sense of NIST/IEEE? What are the advantages and disadvantages, and how does this extended functionality fit within the OGC family of standards?
* Federated Cloud Analytics: How to bring SCALE and SEED into the family of cloud architectures supported by OGC standards? What role does WPS play? What catalog solutions work best?
* EOC, SCALE, and SEED: How to handle the different approaches for cloud processing? Where are harmonization opportunities, what needs to remain separate?
* Federated Clouds Provenance: How can Blockchain and distributed ledger technologies be used to protect the integrity of different types of provenance data?

There are individual Engineering Report that describes the results of each of these work activities. These information resources are provided below.

[options="header"]
|===
| Information Resource | Location of resource
| Requirements | https://portal.opengeospatial.org/files/?artifact_id=82290#FederatedCloudAnalytics[CFP Sponsor Requirements for Federated Cloud Analytics]
| Engineering Reports | http://docs.opengeospatial.org/per/19-024r1.html[Federated Clouds Security Engineering Report] +
      http://docs.opengeospatial.org/per/19-026.html[Federated Clouds Analytics Engineering Report] +
      http://docs.opengeospatial.org/per/19-022r1.html[Scaling Units of Work (EOC, Scale, SEED) Engineering Report] +
      http://docs.opengeospatial.org/per/19-015.html[Federated Cloud Provenance Engineering Report]
| Power Point Presentation | link:https://github.com/cnreediii/testbed15-summary/blob/master/slides/Testbed%2015%20Federated%20Cloud%20analytics.pdf[Slide presentation]
| Short Video | link:https://portal.opengeospatial.org/files/?artifact_id=91766[OGC Video]
|===

[[CPP]]

=== Thread 2: Cloud Processing and Portrayal (CPP)

[[EOPAD]]

==== Earth Observation Process and Application Discovery

*Researching approaches for users to discover and run the Earth Observation applications they need.*

Over the last decade, several platforms have emerged that provide access to Earth Observation data and processing capacities. These platforms host very large (peyabyte) datasets. As such, a paradigm shift from data download and local processing towards application upload and processing close to the physical local of the data is now critical. To interpret peta- or exascale scientific data, capabilities of these platforms need to be combined in future.

Hence, the focus of Testbed-15 work was to define the building blocks through which such applications and related services can be exposed through a Catalogue service. Within that overarching goal, the Testbed particpants described and demonstrated how OGC standards can be used or need to be extended to provide for discovery and use of EO data processing applications that can be deployed and executed by the user or are already deployed and available behind standardized OGC interfaces. The particpants also demonstrated how existing and emerging systems as deployed by NASA (e.g. NASA DAACs and NASA DASS), ESA (ESA TEPs) or systems that have already integrated various nodes such as the Earth System Grid Federation (ESGF) can be federated to allow for cross-platform analysis and visualization of data.

The results of this work, documented in the Engineering Report, define the building blocks through which such applications and related services can be exposed through a Catalogue service, including:

* A Data model.
* Service interfaces.
* A Service management interface.

The key findings from the work include:

* The bindings for the proposed Catalogue and GeoJSON Data Model are consistent with existing OGC Standards related to OWS Context and OGC Extensions of OpenSearch.
* Support for facet discovery and faceted search responses was borrowed from existing OASIS SRU specifications and the http://docs.opengeospatial.org/per/19-020r1.html#SRU-Extension[SRU extension of OpenSearch].
* The proposed Data Model relies on OGC OWS Context [OGC14-055r2] Offerings to describe service or application access mechanisms and endpoints.
* In addition to the GeoJSON-based model, the corresponding JSON-LD representation is proposed as well in this ER. A service or application described in the catalog is modelled as a dcat:DataService in [DCAT-2].

The following are additional information resources regarding the Data Centric Security task.

[options="header"]
|===
| Information Resource | Location of resource
| Requirements | https://portal.opengeospatial.org/files/?artifact_id=82290#EOPAD[CFP Sponsor Requirements for Earth Observation Process and Application Discovery]
| Engineering Report(s) |http://docs.opengeospatial.org/per/19-020r1.html[Catalogue and Discovery Engineering Report]
| Power Point Presentation | link:https://github.com/cnreediii/testbed15-summary/blob/master/slides/Testbed%2015%20Earth%20Observation%20Task.pdf[Slide presentation]
|===

[[OPF]]

==== Open Portrayal Framework

*Define the Models, APIs, and Architecture to Support and enable Open and Interoperable Portrayal.*

Interoperable, dynamic portrayal of maps and related geospatial data is still challenging when working across multiple computing, rendering, communications and display environments.  Despite the previous efforts the OGC is still missing a robust conceptual model and related APIs capable of supporting multiple style encodings and the style encodings themselves. 

Therefore, the primary topics addressed in the OPF thread covered supporting style sharing and updates, client- and server-side rendering of both vector- and raster data, and converting styles from one encoding to another. This work was based on a draft http://www.opengis.net/doc/PER/t15-D011[conceptual style model]. In addition, there was a requirement to render data according to style definitions in a denied, disrupted, intermittent, and limited bandwidth (DDIL) infrastructure.

image::images/overviewOPF.png[image,width=380,height=308]
* Overview of the Testbed-15 Open Portrayal Framework major work items *

The goal of the Testbed-15 Open Portrayal Framework thread was to implement a data discovery, access, and styled rendering scenario. The scenario included data updates performed as a background tasks and support for online/offline functionality. 

image::images/TB15_OPF.png[image,width=380,height=308]
* Result of applying knowledge and draft APIs developed in the OPF Thread *

[options="header"]
|===
| Information Resource | Location of resource
| Requirements | https://portal.opengeospatial.org/files/?artifact_id=82290#Portrayal[CFP Sponsor Requirements for Open Portrayal Framework]
| Engineering Reports | http://docs.opengeospatial.org/per/19-023r1.html[Encoding and Metadata Conceptual Model for Styles Engineering Report] +
     http://docs.opengeospatial.org/per/19-010r2.html[Styles API Engineering Report] +
     http://docs.opengeospatial.org/per/19-069.html[Maps and Tiles API Engineering Report] +
     http://docs.opengeospatial.org/per/19-018.html[Open Portrayal Framework Engineering Report] +
     http://docs.opengeospatial.org/per/19-070.html[Images and Changes Set API Engineering Report] +
     http://docs.opengeospatial.org/per/19-019.html[Portrayal Summary Engineering Report]
| Power Point Presentation | link:https://github.com/cnreediii/testbed15-summary/blob/master/slides/Testbed%2015%20Open%20Portrayal%20Framework.pdf[Slide presentation]
| Short Videos | link:https://www.youtube.com/watch?v=igtXZcHgqfQ[Example of using draft OGC Tiles API] +
      link:https://www.youtube.com/watch?v=jToYiE89cSA[Example of using draft Styles API]
|===

[[MLD]]

=== Thread 3: Machine Learning and Delta Updates (MLD)

[[Machine Learning]]

==== Machine Learning

*Develop a set of machine learning models and explore their usage within OGC Web service based environments.*

The synergies obtained by integrating machine learning/deep learning (DL/ML) with geospatial analysis, also known as GeoAI, is providing ever increasing societal value. Applications such as quickly identifying diseased timber, diffusion of viral infections, or avalanche risk analysis are already providing value and saving lives. However, much work remains to continue to both evolve the geospatial and ML/DL synergy. Issues such as how can training be optimized and what role do standards have need to be answered. A large variety of geospatial data are available through standardized OGC interfaces that could facilitate the discovery and access to datasets used to feed ML tools.

Therefore, the OGC Testbed-15 Machine Learning (ML) task explored the utility of existing OGC Web services (OWS) to support a large scope of ML tools including EO data processing, image classification, feature extraction and vector attribution. The key research question was how these various ML models can be integrated best within standards-based infrastructures. These infrastructures include OGC Web services that interface any kind of data repository from rather stable image archives to Big data sensor data archives or real time systems.

The research involved implementing five different scenarios. Each scenario focused on a different machine learning challenge and prototype were implemented as an individual demonstrations. The five scenarios were:

* Petawawa Super Site research forest change prediction ML model. As a first step towards an automated forest change prediction system, participants developed prototype capability and demonstrated the use of Machine Learning to remove clouds and high altitude cloudets (popcorn clouds) from historical datasets for the http://www.forestresearch.ca/index.php?option=com_content&view=article&id=272&Itemid=83[Petawawa super site].
* New Brunswick forest supply management decision maker ML model. For this scenario, particpants delivered a forest supply management decision maker ML model for the province of New Brunswick forested areas. This included recommending the most efficient optimized path from forest to market -”wood flow model” and recommending new road construction that will be the most efficient over time and safety being considered. 
* Quebec lake - river differentiation ML model. Participants delivered an ML model that delineated lake and river features from an undifferentiated waterbody vector dataset.
* Richelieu River hydro linked data harvest model. The participants developed a semantically driven ML capability to harvest hydrological relations from the web for the Richelieu River / Watershed area. The harvesting process used a variety of data sources. 
* Arctic web services discovery ML model. The participants delivered a component capable of building an evergreen catalogue of relevant arctic circumpolar Web services. The goal was to develop a machine learning model that could perform such activities as discover OGC and Esri REST Web services that have some relevance to circumpolar science and evaluate the confidence level of each recommended service using both metadata and data parameters.

[options="header"]
|===
| Information Resource | Location of resource
| Requirements | https://portal.opengeospatial.org/files/?artifact_id=82290#MachineLearning[CFP Sponsor Requirements for Machine Learning]
| Engineering Report(s) |http://docs.opengeospatial.org/per/19-027r2.html[Machine Learning Engineering Report] +
                         http://docs.opengeospatial.org/per/19-021.html[Semantic Web Link Builder and Triple Generator Engineering Report] +
                         http://docs.opengeospatial.org/per/19-020r1.html[Catalogue and Discovery Engineering Report]
| Power Point Presentation | link:https://github.com/cnreediii/testbed15-summary/blob/master/slides/Testbed%2015%20Machine%20Learning.pdf[Slide presentation]
| Short Video | link:https://www.youtube.com/watch?v=k6Gdem41Zw8[Youtube Video of New Brunswick Forest ML Model]
|===

[[DeltaUpdates]]

==== Delta Updates

*Explore how changes (updates) to geospatial data can be securely provided to users in the field*

In today's world, geosaptial data is collected and updated at an ever increasing pace. In many application domains, users require these updated data as quickly as possible. First responders, wild fire repsonse teams, war fighters, extreme sports enthusiasts and more all need the latest and best content - including near real time updates.

The key research question in the Delta Updates task was how to implement reliable and secure delta update mechanisms with OGC next generation Web Services such as http://docs.opengeospatial.org/is/17-069r3/17-069r3.html[OGC API - Features - Part 1: Core] (aka WFS 3.0) and the draft https://github.com/opengeospatial/wps-rest-binding[OGC API - Processes] (aka WPS 3.0). The research included exploring different mechanisms that either require enhancements to existing WFS 3.0 instances or use to be developed WPS 3.0 instances to realize similar functionality without touching existing data access services.

The Delta Updates participants designed and documented a service architecture that allows the delivery of prioritized updates of features to a client, possibly acting in a DDIL (Denied, Degraded, Intermitted or Limited Bandwidth) environment. Two different technical scenarios were investigated and tested:

* The enhancement of Web Feature Service (WFS) instances to support updates on features sets.
* Utilizing a Web Processing Service (WPS) instance to access features, without the need to modify the downstream data service.

image::images/DeltaUpdates.png[image,width=380,height=308]

In the Delta Updates ER, the participants document how prioritized delta updates can be served using a transactional extension to the OGC API – Features and the WPS standard/OGC API – Processes in front of WFS instances. Both approaches use the same algorithm to keep track of the changes to the dataset.

[options="header"]
|===
| Information Resource | Location of resource
| Requirements | https://portal.opengeospatial.org/files/?artifact_id=82290#DeltaUpdates[CFP Sponsor Requirements for Delta Updates]
| Engineering Report(s) |http://docs.opengeospatial.org/per/19-012r1.html[Delta Updates Engineering Report]
| Power Point Presentation | link:https://github.com/cnreediii/testbed15-summary/blob/master/slides/Testbed%2015%20Delta%20Updates.pdf[Slide presentation]
| Short Video | link:https://www.youtube.com/watch?v=Ka_xCszws1A&list=PLQsQNjNIDU85HBDZWc8aE7EvQKE5nIedK&index=8&t=0s[Youtube Video]
|===
