[[thread-summaries]]

== Thread Summaries

The following are overviews of each of the major Testbed 15 thread activities.

[[SFC]]

=== Thread 1: Secure Data and Federated Clouds (SFC)

==== Data Centric Security

*Explore How Data Centric Security principals can be applied at the feature level in a geospatial data store.*

Data-centric security is an approach to security that emphasizes the security of the data itself rather than the security of networks, servers, or applications. In Testbed-15, the focus was on how security works at a Feature Level as well as implications as a data burden on the network. With focus on the actual interactions and general workflows, Testbed-15 work sought to answer the question of how data centric security can be applied to OGC standards based architectures:

* How does data centric security works with OGC standards and best practices?
* Which elements are already supported and how?
* Which modifications to existing standards or best practices are necessary to exploit full potential of data centric security?

To answer those questions, the particpants examined the use of encrypted containers in combination with geospatial data using the encoding for an OGC API for Features and the Web Feature Service (WFS) FeatureCollection structure. Within that context, the particants looked at the use of encrypted container formats such as NATO STANAG 4778 "Information on standard Metadata Binding" with metadata as defined in NATO STANAG 4774 "Confidentiality Metadata Label Syntax" to permit the sharing of sensitive information between allies.

image::images/GepPEP as a Proxy for STANAG 4778.png[image,width=326,height=308]
* Geospatial Policy Enforcement Point (GeoPEP) as a Proxy for STANAG 4778 *

In general, the work performed in Testbed 15 was able to demonstrate that with a security proxy and an OGC API - Features service, an implementation can satisfy the requirements for a data centric security model. The Engineering Report documents the results of implementing three scenarios. Scenarios one and two show a backward compatible method for implementing data centric security. One requirement that was not completely investigated in the first two scenarios was encryption of the data from the author to storage. 

The following are additional information resources regarding the Data Centric Security task.

[options="header"]
|===
| Information Resource | Location of resource
| Engineering Report(s) |http://docs.opengeospatial.org/per/19-016r1.html[Data Centric Security Engineering Report]
| Power Point Presentation | link:https://github.com/cnreediii/testbed15-summary/blob/master/slides/Testbed%2015%20Data%20Centric%20Security.pdf[Slide presentation]
| Short Video | link:https://www.youtube.com/watch?v=5_ynVa8ZMY4&list=PLQsQNjNIDU85HBDZWc8aE7EvQKE5nIedK&index=7&t=0s[Youtube Video]
|===

==== Federated Cloud Analytics

The advent of the cloud computing era has fundamentally changed how people and organizations view computing — and more specifically how people and organizations interact with the resources that they care about: data and services. All computing resources, including clouds, exist in some type of administrative domain wherein access management can be done. As long as resources are all in the same administrative domain, managing access is straight-forward. However, with the continued development of our interconnected world, it is becoming increasingly common that data and services desired by a user exist across different administrative domains.

Easily accessing resources distributed across different administrative domains is a challenge. The naive approach is for an individual to maintain n different accounts and credentials for n different organizations. A more effective approach is federation.

Simply put, a federation enables a set of participating organizations to selectively share data and resources for specific purposes. The goal is to make federated environments as seamless, transparent, and easy to use as a single centralized environment. More precisely, a federation is a security and collaboration context wherein participants can define, agree up on, and enforce joint resource discovery and access policies.

Previous OGC Testbeds addressed a number of issues related to supporting analytic workflows where the data and analytics are hosted or deployed in an ad-hoc manner on multiple heterogeneous clouds that belong to different administrative domains. In this Testbed activity the OGC began to assess the sufficiency of that body of work and identify areas were additional work is needed. This assessment was performed through a proof of concept executing a non-trivial analytic mission leveraging data and analytics hosted on two or more clouds.

Of particular interest in this context are three aspects. Firstly, the handling of security in federations. Second, how the Testbed-13 and Testbed-14 research results of "bringing applications to the data" relate to SCALE and SEED. SCALE is an open source system that provides management and scheduling of automated processing on a cluster of machines. SCALE uses the SEED specification to aid in the discovery and consumption of processes packaged in a Docker containers. Third, the role of blockchain and distributed ledger technologies in the context of handling provenance in federations.

To meet this objective, this task was organized in four separate sub-tasks. The following research questions were addressed by the particpants:

* Federated Security: Can the NIST/IEEE Federated Cloud architecture be validated (or invalidated) in a typical federated clouds analytics scenario that includes separate cloud environments? How can the Mediation Server concept developed in Testbed-14 be further enhanced to a fully functional Federation Manager in the sense of NIST/IEEE? What are the advantages and disadvantages, and how does this extended functionality fit within the OGC family of standards?
* Federated Cloud Analytics: How to bring SCALE and SEED into the family of cloud architectures supported by OGC standards? What role does WPS play? What catalog solutions work best?
* EOC, SCALE, and SEED: How to handle the different approaches for cloud processing? Where are harmonization opportunities, what needs to remain separate?
* Federated Clouds Provenance: How can Blockchain and distributed ledger technologies be used to protect the integrity of different types of provenance data?

There are individual Engineering Report that describes the results of each of these work activities. These information resources are provided below.

[options="header"]
|===
| Information Resource | Location of resource
| Engineering Report(s) | http://docs.opengeospatial.org/per/19-024r1.html[Federated Clouds Security Engineering Report] +
      http://docs.opengeospatial.org/per/19-026.html[Federated Clouds Analytics Engineering Report] +
      http://docs.opengeospatial.org/per/19-022r1.html[Scaling Units of Work (EOC, Scale, SEED) Engineering Report] +
      http://docs.opengeospatial.org/per/19-015.html[Federated Cloud Provenance Engineering Report]
| Power Point Presentation | link:https://github.com/cnreediii/testbed15-summary/blob/master/slides/Testbed%2015%20Federated%20Cloud%20analytics.pdf[Slide presentation]
| Short Video | link:https://portal.opengeospatial.org/files/?artifact_id=91766[OGC Video]
|===

[[CPP]]

=== Thread 2: Cloud Processing and Portrayal (CPP)

==== Earth Observation Process and Application Discovery

==== Open Portrayal Framework

[[MLD]]

=== Thread 3: Machine Learning and Delta Updates (MLD)

==== Machine Learning

The synergies obtained by integrating machine learning/deep learning (DL/ML) with geospatial analysis, also known as GeoAI, is providing ever increasing societal value. Applications such as quickly identifying diseased timber, diffusion of viral infections, or avalanche risk analysis are already providing value and saving lives. However, much work remains to continue to both evolve the geospatial and ML/DL synergy. Issues such as how can training be optimized and what role do standards have need to be answered. A large variety of geospatial data are available through standardized OGC interfaces that could facilitate the discovery and access to datasets used to feed ML tools.

Therefore, the OGC Testbed-15 Machine Learning (ML) task explored the utility of existing OGC Web services (OWS) to support a large scope of ML tools including EO data processing, image classification, feature extraction and vector attribution. The key research question was how these various ML models can be integrated best within standards-based infrastructures. These infrastructures include OGC Web services that interface any kind of data repository from rather stable image archives to Big data sensor data archives or real time systems.

The research involved implementing five different scenarios. Each scenario focused on a different machine learning challenge and prototype were implemented as an individual demonstrations. The five scenarios were:

* Petawawa Super Site research forest change prediction ML model. As a first step towards an automated forest change prediction system, participants developed prototype capability and demonstrated the use of Machine Learning to remove clouds and high altitude cloudets (popcorn clouds) from historical datasets for the http://www.forestresearch.ca/index.php?option=com_content&view=article&id=272&Itemid=83[Petawawa super site].
* New Brunswick forest supply management decision maker ML model. For this scenario, particpants delivered a forest supply management decision maker ML model for the province of New Brunswick forested areas. This included recommending the most efficient optimized path from forest to market -”wood flow model” and recommending new road construction that will be the most efficient over time and safety being considered. 
* Quebec lake - river differentiation ML model. Participants delivered an ML model that delineated lake and river features from an undifferentiated waterbody vector dataset.
* Richelieu River hydro linked data harvest model. The participants developed a semantically driven ML capability to harvest hydrological relations from the web for the Richelieu River / Watershed area. The harvesting process used a variety of data sources. 
* Arctic web services discovery ML model. The participants delivered a component capable of building an evergreen catalogue of relevant arctic circumpolar Web services. The goal was to develop a machine learning model that could perform such activities as discover OGC and Esri REST Web services that have some relevance to circumpolar science and evaluate the confidence level of each recommended service using both metadata and data parameters.

[options="header"]
|===
| Information Resource | Location of resource
| Engineering Report(s) |http://docs.opengeospatial.org/per/19-027r2.html[Machine Learning Engineering Report] +
                         http://docs.opengeospatial.org/per/19-021.html[Semantic Web Link Builder and Triple Generator Engineering Report] +
                         http://docs.opengeospatial.org/per/19-020r1.html[Catalogue and Discovery Engineering Report]
| Power Point Presentation | link:https://github.com/cnreediii/testbed15-summary/blob/master/slides/Testbed%2015%20Machine%20Learning.pdf[Slide presentation]
| Short Video | link:https://www.youtube.com/watch?v=k6Gdem41Zw8[Youtube Video of New Brunswick Forest ML Model]
|===

==== Delta Updates

